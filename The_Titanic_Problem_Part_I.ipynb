{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuG4f/Br0EOeYs6cZuGDU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlvckSanek/The_Titanic_Problem/blob/main/The_Titanic_Problem_Part_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hello World!, This is my attempt at tackling the titanic problem as an ML beginner."
      ],
      "metadata": {
        "id": "tlsMgXnZAPA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We will start off by creating an authentication to kaggle's API and download the titanic dataset."
      ],
      "metadata": {
        "id": "TPY_2V-5BGrz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGERWVBw_qo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200f93cd-3bdb-4ec5-e6ed-3de15d21bb4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "kX5VAK21Dm5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "g-BGIMpTEegK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSL733HaD0Ni",
        "outputId": "3db6ba93-c713-41e3-fceb-1748345fa639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading titanic.zip to /content\n",
            "\r  0% 0.00/34.1k [00:00<?, ?B/s]\n",
            "\r100% 34.1k/34.1k [00:00<00:00, 2.70MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip titanic.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB89nJdHFfMJ",
        "outputId": "634c9657-7509-4a9f-de2b-960aab478eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  titanic.zip\n",
            "  inflating: gender_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now import the neccesary python packages to help us in our voyage."
      ],
      "metadata": {
        "id": "zWlAvwuHFuM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import rcParams\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = 10,8\n",
        "sns.set(style='whitegrid', palette='muted',\n",
        "        rc={'figure.figsize': (12,8)})"
      ],
      "metadata": {
        "id": "aTf7H5eNF7k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data into pandas dataframe"
      ],
      "metadata": {
        "id": "y76QMTxyGKK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "22oFffyKGGcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will go ahead and check the dataset for missing values and find the best way to deal with them."
      ],
      "metadata": {
        "id": "TEsGqSrWG62d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.isnull().sum())\n",
        "print()\n",
        "print(test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTSLLwdAG6Gc",
        "outputId": "b090d7f4-c28f-4e87-bba4-4f4b866bc8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note whatever preprocessing steps we take wpuld be applied to the testing datasets too. Very Important."
      ],
      "metadata": {
        "id": "gsJVLMabIJRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could see that Age, Cabin and Embarked have some missing values. We will deal with variables separately. For the Age we can simply impute the median for all the missing values but that would not be the best approach. Cabin we would tackle it differently, we talk more about it later. Embarked would just use pandas backfill to handle that. There might be better approach but for now these are the steps I would be taking."
      ],
      "metadata": {
        "id": "2j0SWlIAIWgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First off, Age variable. The approach here is to create a new variable called Title and group the dataset by the titles and compute the median for the groups. We will then use the grouped mean for all the titles to impute the missing values. We are killing two birds with one stone.\n",
        "To get the titles we can utilize regular expression to help us extract the titles from the Name column."
      ],
      "metadata": {
        "id": "y36iAP3jJzrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Title\"] = train[\"Name\"].str.extract(\"([A-Za-z]+)\\.\", expand=True)\n",
        "test[\"Title\"] = test[\"Name\"].str.extract(\"([A-Za-z]+)\\.\", expand=True)"
      ],
      "metadata": {
        "id": "daBHg5Z0HLw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is done, so we will check the unique titles in the Title variable and see what we can infer from it."
      ],
      "metadata": {
        "id": "pdUoFUgcMXfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.Title.value_counts(), end=\"\\n\\n\")\n",
        "print(test.Title.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e8ij5NAL4fC",
        "outputId": "60a84b24-4e71-4d6e-9179-6906e37cf215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title\n",
            "Mr          517\n",
            "Miss        182\n",
            "Mrs         125\n",
            "Master       40\n",
            "Dr            7\n",
            "Rev           6\n",
            "Mlle          2\n",
            "Major         2\n",
            "Col           2\n",
            "Countess      1\n",
            "Capt          1\n",
            "Ms            1\n",
            "Sir           1\n",
            "Lady          1\n",
            "Mme           1\n",
            "Don           1\n",
            "Jonkheer      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Title\n",
            "Mr        240\n",
            "Miss       78\n",
            "Mrs        72\n",
            "Master     21\n",
            "Col         2\n",
            "Rev         2\n",
            "Ms          1\n",
            "Dr          1\n",
            "Dona        1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It turns out that most these titles are just French versions of the common English titles, e.g Mme = Madame = Lady = Mrs. We will group the titles into six most common titles by replacing other titles with the appropriate of these six."
      ],
      "metadata": {
        "id": "vTsV-n4umnP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping to replace the rare titles with their appropriate titles in English\n",
        "mapping = {\n",
        "    \"Mlle\": \"Miss\", \"Major\": \"Mr\", \"Col\": \"Mr\", \"Sir\": \"Mr\",\n",
        "    \"Don\": \"Mr\", \"Mme\": \"Mrs\", \"Jonkheer\": \"Mr\", \"Lady\": \"Mrs\",\n",
        "    \"Capt\": \"Mr\", \"Countess\": \"Mrs\", \"Ms\": \"Miss\", \"Dona\": \"Mrs\"\n",
        "}\n",
        "train.replace({\"Title\": mapping}, inplace=True)\n",
        "test.replace({\"Title\": mapping}, inplace=True)"
      ],
      "metadata": {
        "id": "DpFnZmsdMv6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.Title.value_counts(), end=\"\\n\\n\")\n",
        "print(test.Title.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bNtLJsVpkbB",
        "outputId": "d436ef63-94af-4e98-c49c-28f7b03a15fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title\n",
            "Mr        525\n",
            "Miss      185\n",
            "Mrs       128\n",
            "Master     40\n",
            "Dr          7\n",
            "Rev         6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Title\n",
            "Mr        242\n",
            "Miss       79\n",
            "Mrs        73\n",
            "Master     21\n",
            "Rev         2\n",
            "Dr          1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the median of the title group.\n",
        "We can now go ahead fill the missing ages with the medians of each title group."
      ],
      "metadata": {
        "id": "4zDJAtFPp7mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_title_ages = dict(train.groupby(\"Title\")[\"Age\"].median())\n",
        "group_title_ages = dict(test.groupby(\"Title\")[\"Age\"].median())\n",
        "\n",
        "# Create a new column called average age to assit us in our task\n",
        "train[\"Med_Age\"] = train[\"Title\"].apply(lambda x: group_title_ages[x])\n",
        "test[\"Med_Age\"] = test[\"Title\"].apply(lambda x: group_title_ages[x])\n",
        "\n",
        "# Impute all the missing ages with the value in age column\n",
        "train.Age.fillna(train[\"Med_Age\"], inplace=True)\n",
        "test.Age.fillna(test[\"Med_Age\"], inplace=True)\n",
        "\n",
        "# Drop the temporary created column\n",
        "train.drop(\"Med_Age\", axis=1, inplace=True)\n",
        "test.drop(\"Med_Age\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "_eocBaxep6lh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are done with the Age variable. On to the next which the Fare variable."
      ],
      "metadata": {
        "id": "_63nbu0vtisr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with the fare missing values"
      ],
      "metadata": {
        "id": "3NySpMi8xinm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the median to impute for the missing values in the same approach as we did for the Age variable."
      ],
      "metadata": {
        "id": "H6lW7azzuA4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fares_class = dict(train.groupby(\"Pclass\")[\"Fare\"].median())\n",
        "fares_class = dict(test.groupby(\"Pclass\")[\"Fare\"].median())\n",
        "\n",
        "# Create a new column called Med_fare to help us in our task\n",
        "train[\"Med_Fare\"] = train[\"Pclass\"].apply(lambda x: fares_class[x])\n",
        "test[\"Med_Fare\"] = test[\"Pclass\"].apply(lambda x: fares_class[x])\n",
        "\n",
        "# Impute for the missing values\n",
        "train.Fare.fillna(train[\"Med_Fare\"], inplace=True,)\n",
        "test.Fare.fillna(test[\"Med_Fare\"], inplace=True,)"
      ],
      "metadata": {
        "id": "GLUh243StzwM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop new column created\n",
        "train.drop(\"Med_Fare\", axis=1, inplace=True)\n",
        "test.drop(\"Med_Fare\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "N_s45CbuvUGp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with Embarked missing values"
      ],
      "metadata": {
        "id": "nv4lXPMzxYI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this there are only 2 missing values in the training dataset so my approach is to use Pandas \"backfill\" method. The test dataset is okay so nothing would be done to it."
      ],
      "metadata": {
        "id": "q37r3HWmyBsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Embarked\"].fillna(method=\"backfill\", inplace=True)"
      ],
      "metadata": {
        "id": "2MF3F9jBxy81"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with the Cabin variable's missing values"
      ],
      "metadata": {
        "id": "G0j-3TBIz31x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The approach is to extract the Deck variable attached to the Cabin variables and create a new column called Deck. We will then go ahead and drop the Cabin varible. Also for now, my approach is fill missing values with \"Missing\" in the Deck column."
      ],
      "metadata": {
        "id": "C0YA5WkPz_8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function that would be use to extract the variables\n",
        "def extract_deck(cabin):\n",
        "    if isinstance(cabin, str):\n",
        "        return cabin[0]\n",
        "    else:\n",
        "        return \"Missing\"\n",
        "\n",
        "train[\"Deck\"] = train[\"Cabin\"].apply(extract_deck)"
      ],
      "metadata": {
        "id": "vPl2mlEv2Qv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(\"Cabin\", axis=1, inplace=True)\n",
        "test.drop(\"Cabin\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "qGoeMwM_67-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let us add family size variable to the data"
      ],
      "metadata": {
        "id": "SiiVOpQ9yvog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can achieve this by adding the `Parch` and `SibSp` variables together to get the `Family_Size` variable."
      ],
      "metadata": {
        "id": "VOpihsoNzDVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Family_Size variable\n",
        "train[\"Family_Size\"] = train.Parch + train.SibSp\n",
        "test[\"Family_Size\"] = test.Parch + train.SibSp"
      ],
      "metadata": {
        "id": "grW3HjqWyeHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check to see if all the missing values have been filled in our data."
      ],
      "metadata": {
        "id": "Sd9zpbHh-BnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.isnull().sum(), end=\"\\n\\n\")\n",
        "print(test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNjP6Tho9qy-",
        "outputId": "027df9d7-daec-43cd-d391-eab8c9f34ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "Title          0\n",
            "Med_Age        0\n",
            "Family_Size    0\n",
            "dtype: int64\n",
            "\n",
            "PassengerId    0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "Title          0\n",
            "Med_Age        0\n",
            "Family_Size    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let us save our cleaned datasets for future analysis and modelling."
      ],
      "metadata": {
        "id": "GwFL5EO2IpR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(\"train_cleaned.csv\", index=False)\n",
        "test.to_csv(\"test_cleaned.csv\", index=False)"
      ],
      "metadata": {
        "id": "2oBhswzkI5iJ"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}